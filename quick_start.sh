#!/bin/bash

# å¤šç»´å›¾ç‰‡åˆ†æLLMé¡¹ç›® - å¿«é€Ÿå¯åŠ¨è„šæœ¬
# ä½¿ç”¨æ–¹æ³•: ./quick_start.sh [é€‰é¡¹]

echo "ğŸš€ å¤šç»´å›¾ç‰‡åˆ†æLLMé¡¹ç›® - å¿«é€Ÿå¯åŠ¨"
echo "=================================="

# æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
if [ ! -d "training_v1" ] || [ ! -d "training_v2" ]; then
    echo "âŒ é”™è¯¯ï¼šè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬"
    exit 1
fi

# æ˜¾ç¤ºèœå•
show_menu() {
    echo ""
    echo "è¯·é€‰æ‹©è¦æ‰§è¡Œçš„æ“ä½œï¼š"
    echo "1) å®‰è£…ä¾èµ–åŒ…"
    echo "2) ä½¿ç”¨å·²è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†"
    echo "3) ä½¿ç”¨ä¿®æ­£æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹"
    echo "4) æŸ¥çœ‹é¡¹ç›®ç»“æ„"
    echo "5) æŸ¥çœ‹è®­ç»ƒç»“æœ"
    echo "6) æµ‹è¯•æ¨¡å‹åŠ è½½"
    echo "0) é€€å‡º"
    echo ""
    read -p "è¯·è¾“å…¥é€‰é¡¹ (0-6): " choice
}

# å®‰è£…ä¾èµ–
install_dependencies() {
    echo "ğŸ“¦ å®‰è£…ä¾èµ–åŒ…..."
    cd training_v1
    pip install -r requirements.txt
    cd ..
    echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ"
}

# æ¨ç†
run_inference() {
    echo "ğŸ¤– å¯åŠ¨æ¨ç†æ¨¡å¼..."
    cd training_v1
    if [ -d "outputs/best_model" ]; then
        echo "ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œæ¨ç†..."
        python inference.py --model_path outputs/best_model --mode generate
    else
        echo "âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹"
    fi
    cd ..
}

# é‡æ–°è®­ç»ƒ
retrain_model() {
    echo "ğŸ‹ï¸ ä½¿ç”¨ä¿®æ­£æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹..."
    cd training_v1
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if [ ! -f "../training_v2/generated_sequences_super_enhanced/sequences_labels_fixed_tail_fixed.jsonl" ]; then
        echo "âŒ æœªæ‰¾åˆ°ä¿®æ­£åçš„è®­ç»ƒæ•°æ®"
        cd ..
        return
    fi
    
    echo "å¼€å§‹è®­ç»ƒ..."
    python train_gpt.py \
        --data_path ../training_v2/generated_sequences_super_enhanced/sequences_labels_fixed_tail_fixed.jsonl \
        --vocab_path generated_sequences_super_enhanced/vocab.json \
        --batch_size 16 \
        --num_epochs 30 \
        --learning_rate 1e-4 \
        --max_length 512
    
    cd ..
}

# æŸ¥çœ‹é¡¹ç›®ç»“æ„
show_structure() {
    echo "ğŸ“ é¡¹ç›®ç»“æ„ï¼š"
    echo ""
    tree -L 3 -I '__pycache__|*.pyc|.git' || find . -type d -maxdepth 3 | head -20
}

# æŸ¥çœ‹è®­ç»ƒç»“æœ
show_results() {
    echo "ğŸ“Š è®­ç»ƒç»“æœï¼š"
    echo ""
    if [ -d "training_v1/outputs" ]; then
        echo "æ¨¡å‹è¾“å‡ºç›®å½•ï¼š"
        ls -la training_v1/outputs/
        echo ""
        if [ -d "training_v1/training_plots" ]; then
            echo "è®­ç»ƒå›¾è¡¨ï¼š"
            ls -la training_v1/training_plots/
        fi
    else
        echo "âŒ æœªæ‰¾åˆ°è®­ç»ƒè¾“å‡ºç›®å½•"
    fi
}

# æµ‹è¯•æ¨¡å‹åŠ è½½
test_model() {
    echo "ğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½..."
    cd training_v1
    
    if [ -d "outputs/best_model" ]; then
        echo "æµ‹è¯•åŠ è½½æœ¬åœ°æ¨¡å‹..."
        python -c "
from transformers import GPT2LMHeadModel, GPT2Tokenizer
try:
    model = GPT2LMHeadModel.from_pretrained('outputs/best_model')
    tokenizer = GPT2Tokenizer.from_pretrained('outputs/best_model')
    print('âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼')
except Exception as e:
    print(f'âŒ æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}')
"
    else
        echo "âŒ æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹"
    fi
    
    echo "æµ‹è¯•åŠ è½½Hugging Faceæ¨¡å‹..."
    python -c "
from transformers import GPT2LMHeadModel, GPT2Tokenizer
try:
    model = GPT2LMHeadModel.from_pretrained('ludandaye/gpt-causal-lm')
    tokenizer = GPT2Tokenizer.from_pretrained('ludandaye/gpt-causal-lm')
    print('âœ… Hugging Faceæ¨¡å‹åŠ è½½æˆåŠŸï¼')
except Exception as e:
    print(f'âŒ Hugging Faceæ¨¡å‹åŠ è½½å¤±è´¥: {e}')
"
    
    cd ..
}

# ä¸»å¾ªç¯
while true; do
    show_menu
    
    case $choice in
        1)
            install_dependencies
            ;;
        2)
            run_inference
            ;;
        3)
            retrain_model
            ;;
        4)
            show_structure
            ;;
        5)
            show_results
            ;;
        6)
            test_model
            ;;
        0)
            echo "ğŸ‘‹ å†è§ï¼"
            exit 0
            ;;
        *)
            echo "âŒ æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©"
            ;;
    esac
    
    echo ""
    read -p "æŒ‰å›è½¦é”®ç»§ç»­..."
done
