# GPTè¯­è¨€æ¨¡å‹è®­ç»ƒé¡¹ç›®

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®ä½¿ç”¨ HuggingFace Transformers ä»é›¶è®­ç»ƒä¸€ä¸ªå°å‹ GPT è¯­è¨€æ¨¡å‹ï¼Œå®ç°**å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal LMï¼‰**ä»»åŠ¡ï¼šç»™å®šå‰æ–‡tokensåºåˆ—ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªtokenã€‚

## ä»»åŠ¡ç±»å‹è¯´æ˜

### ğŸ¯ ä¸»è¦ä»»åŠ¡ï¼šå› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal LMï¼‰
- **ç›®æ ‡**: ç»™å®šå‰æ–‡ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼ˆé€ä½ç½®å³ç§»æ ‡ç­¾ï¼‰
- **é€‚ç”¨åœºæ™¯**: æ¨¡å‹å¯ä»¥"ç»­å†™/ç”Ÿæˆ"tokenåºåˆ—
- **è®­ç»ƒæ–¹å¼**: LMå¤´ + äº¤å‰ç†µæŸå¤±ï¼Œå¯¹æ¯ä¸ªä½ç½®è¿›è¡Œç›‘ç£ï¼ˆpadä½ç½®è®¾label=-100ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**: Perplexity (PPL)ã€next-token accuracy
- **æ¨ç†æ–¹å¼**: è‡ªå›å½’è§£ç ï¼ˆgreedy/top-k/nucleus samplingï¼‰

### ğŸ”„ å¯é€‰ä»»åŠ¡ï¼šåºåˆ—åˆ†ç±»
- **ç›®æ ‡**: ä½¿ç”¨åºåˆ—çš„æœ€åä¸€ä¸ªtokenè¿›è¡Œ10ç±»åˆ†ç±»ï¼ˆæ•°å­—0-9ï¼‰
- **é€‚ç”¨åœºæ™¯**: åºåˆ—çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡
- **è®­ç»ƒæ–¹å¼**: åˆ†ç±»å¤´ + äº¤å‰ç†µæŸå¤±
- **è¯„ä¼°æŒ‡æ ‡**: åˆ†ç±»å‡†ç¡®ç‡ã€F1åˆ†æ•°
- **æ¨ç†æ–¹å¼**: å‰å‘ä¼ æ’­å¾—åˆ°åˆ†ç±»æ¦‚ç‡

## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ train_gpt.py          # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference.py          # æ¨ç†è„šæœ¬
â”œâ”€â”€ requirements.txt      # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ config.yaml          # è®­ç»ƒé…ç½®æ–‡ä»¶
â”œâ”€â”€ README.md            # é¡¹ç›®è¯´æ˜
â””â”€â”€ generated_sequences_super_enhanced/
    â”œâ”€â”€ sequences_labels_fixed.jsonl  # è®­ç»ƒæ•°æ®
    â””â”€â”€ vocab.json                    # è¯æ±‡è¡¨
```

## ç¯å¢ƒè¦æ±‚

- Python 3.9+
- PyTorch 2.0+
- Transformers 4.41+
- CUDAæ”¯æŒï¼ˆå¯é€‰ï¼Œç”¨äºGPUåŠ é€Ÿï¼‰
- æ”¯æŒ bf16 æ··åˆç²¾åº¦è®­ç»ƒ

## å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹æ³•

### 1. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ
python train_gpt.py

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
python train_gpt.py \
    --data_path generated_sequences_super_enhanced/sequences_labels_fixed.jsonl \
    --vocab_path generated_sequences_super_enhanced/vocab.json \
    --batch_size 16 \
    --num_epochs 30 \
    --learning_rate 1e-4 \
    --max_length 512
```

### 2. æ¨¡å‹æ¨ç†

```bash
# äº¤äº’å¼æ¨ç†ï¼ˆnext-tokené¢„æµ‹ï¼‰
python inference.py --model_path outputs/best_model

# æ–‡æœ¬ç”Ÿæˆæ¨¡å¼
python inference.py --model_path outputs/best_model --mode generate

# æ”¯æŒä¸¤ç§æ¨ç†æ¨¡å¼ï¼š
# - interactive: é¢„æµ‹ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒ
# - generate: è‡ªå›å½’ç”Ÿæˆæ–‡æœ¬
```

## æ¨¡å‹æ¶æ„

- **æ¨¡å‹ç±»å‹**: GPT-2 æ¶æ„ï¼ˆå› æœè¯­è¨€æ¨¡å‹ï¼‰
- **å±‚æ•°**: 6å±‚ Transformer
- **æ³¨æ„åŠ›å¤´æ•°**: 8å¤´
- **åµŒå…¥ç»´åº¦**: 384
- **è¯æ±‡è¡¨å¤§å°**: 516 tokens
- **ä»»åŠ¡ç±»å‹**: å› æœè¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªtokenï¼‰
- **è¾“å‡º**: è¯æ±‡è¡¨æ¦‚ç‡åˆ†å¸ƒï¼ˆ516ç»´ï¼‰

## è®­ç»ƒç‰¹ç‚¹

1. **ä»é›¶è®­ç»ƒ**: ä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œå®Œå…¨ä»å¤´å¼€å§‹è®­ç»ƒ
2. **å°æ¨¡å‹è®¾è®¡**: é’ˆå¯¹æœ‰é™è®¡ç®—èµ„æºä¼˜åŒ–
3. **å› æœè¯­è¨€å»ºæ¨¡**: é¢„æµ‹åºåˆ—ä¸­æ¯ä¸ªä½ç½®çš„ä¸‹ä¸€ä¸ªtoken
4. **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
5. **å­¦ä¹ ç‡è°ƒåº¦**: ä½™å¼¦é€€ç«è°ƒåº¦å™¨
6. **ä½ç½®æ©ç **: ä½¿ç”¨å› æœæ³¨æ„åŠ›æ©ç ï¼Œç¡®ä¿æ¨¡å‹åªèƒ½çœ‹åˆ°å‰æ–‡

## è®­ç»ƒå‚æ•°

- **æ‰¹æ¬¡å¤§å°**: 8ï¼ˆå¯æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼‰
- **å­¦ä¹ ç‡**: 5e-5
- **è®­ç»ƒè½®æ•°**: 20
- **ä¼˜åŒ–å™¨**: AdamW
- **æŸå¤±å‡½æ•°**: CrossEntropyLossï¼ˆè¯­è¨€å»ºæ¨¡ï¼‰
- **æ•°æ®åˆ’åˆ†**: 80%è®­ç»ƒï¼Œ20%éªŒè¯
- **åºåˆ—é•¿åº¦**: æœ€å¤§1024 tokens
- **æ ‡ç­¾å¤„ç†**: padä½ç½®è®¾ä¸º-100ï¼ˆä¸å‚ä¸æŸå¤±è®¡ç®—ï¼‰

## è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåä¼šç”ŸæˆHuggingFaceæ ‡å‡†æ ¼å¼çš„æ¨¡å‹ï¼š

```
outputs/
â”œâ”€â”€ best_model/           # æœ€ä½³éªŒè¯æ€§èƒ½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ config.json       # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ pytorch_model.bin # æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ tokenizer.json    # tokenizeré…ç½®
â”‚   â”œâ”€â”€ special_tokens_map.json
â”‚   â””â”€â”€ training_args.bin # è®­ç»ƒçŠ¶æ€
â””â”€â”€ final_model/          # æœ€ç»ˆè®­ç»ƒå®Œæˆçš„æ¨¡å‹
    â”œâ”€â”€ config.json
    â”œâ”€â”€ pytorch_model.bin
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ special_tokens_map.json
```

### ğŸš€ æ¨¡å‹åŠ è½½æ–¹å¼

```python
# ç›´æ¥ä½¿ç”¨ from_pretrained() åŠ è½½
from transformers import GPT2LMHeadModel, GPT2Tokenizer

model = GPT2LMHeadModel.from_pretrained("outputs/best_model")
tokenizer = GPT2Tokenizer.from_pretrained("outputs/best_model")
```

## æ€§èƒ½é¢„æœŸ

åŸºäºæ•°æ®è´¨é‡ï¼Œé¢„æœŸæ€§èƒ½ï¼š
- **è®­ç»ƒå›°æƒ‘åº¦ (PPL)**: < 2.0
- **éªŒè¯å›°æƒ‘åº¦ (PPL)**: < 2.5
- **Next-tokenå‡†ç¡®ç‡**: 85%+
- **æ”¶æ•›è½®æ•°**: 10-15è½®
- **ç”Ÿæˆè´¨é‡**: èƒ½å¤Ÿç”Ÿæˆè¿è´¯çš„tokenåºåˆ—

## æ³¨æ„äº‹é¡¹

1. ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼ˆå»ºè®®8GB+ï¼‰
2. è®­ç»ƒæ—¶é—´çº¦1-3å°æ—¶ï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
3. æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
4. æ”¯æŒCPUè®­ç»ƒï¼ˆä½†é€Ÿåº¦è¾ƒæ…¢ï¼‰

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**: å‡å°batch_size
2. **è®­ç»ƒä¸æ”¶æ•›**: è°ƒæ•´å­¦ä¹ ç‡æˆ–å¢åŠ è®­ç»ƒè½®æ•°
3. **æ•°æ®åŠ è½½é”™è¯¯**: æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼

### æ€§èƒ½ä¼˜åŒ–

1. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰
2. å¯ç”¨æ¢¯åº¦ç´¯ç§¯
3. ä½¿ç”¨å¤šGPUè®­ç»ƒ

## æ‰©å±•åŠŸèƒ½

- æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹é…ç½®
- å¯æ·»åŠ æ›´å¤šè¯„ä¼°æŒ‡æ ‡ï¼ˆBLEUã€ROUGEç­‰ï¼‰
- æ”¯æŒæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼
- å¯é›†æˆåˆ°WebæœåŠ¡ä¸­
- **æ–‡æœ¬ç”Ÿæˆ**: æ”¯æŒä¸åŒé‡‡æ ·ç­–ç•¥ï¼ˆgreedyã€top-kã€nucleusï¼‰
- **åºåˆ—ç»­å†™**: ç»™å®šå‰ç¼€ï¼Œè‡ªåŠ¨ç”Ÿæˆåç»­å†…å®¹
- **æ¨¡å‹å¾®è°ƒ**: æ”¯æŒåœ¨å…¶ä»–é¢†åŸŸæ•°æ®ä¸Šç»§ç»­è®­ç»ƒ

## è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚
