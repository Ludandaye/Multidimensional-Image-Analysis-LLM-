# GPT因果语言模型训练配置
training:
  # 数据配置
  data_path: "generated_sequences_super_enhanced/sequences_labels_fixed.jsonl"
  vocab_path: "generated_sequences_super_enhanced/vocab.json"
  
  # 训练参数
  batch_size: 8
  num_epochs: 20
  learning_rate: 5e-5
  max_length: 1024
  
  # 模型配置
  model:
    n_layer: 6          # Transformer层数
    n_head: 8           # 注意力头数
    n_embd: 384         # 嵌入维度
    n_positions: 1024   # 位置编码长度
    n_ctx: 1024         # 上下文长度
  
  # 优化器配置
  optimizer:
    weight_decay: 0.01
    gradient_clip: 1.0
  
  # 学习率调度器
  scheduler:
    type: "cosine"
    T_max: 20
  
  # 设备配置
  device: "auto"  # auto, cpu, cuda
  
  # 保存配置
  save:
    save_best: true
    save_final: true
    checkpoint_dir: "./checkpoints"
  
  # 因果语言模型特定配置
  causal_lm:
    # 标签处理
    pad_label: -100      # pad位置的标签值
    # 生成参数
    max_new_tokens: 20   # 生成时的最大新token数
    temperature: 0.8     # 生成温度
    do_sample: true      # 是否使用采样
