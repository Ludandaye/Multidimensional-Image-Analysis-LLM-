import json
import torch
from transformers import GPT2LMHeadModel
import pandas as pd
from collections import defaultdict
import random

def main():
    print('ğŸ¯ æµ‹è¯•æ‰€æœ‰æ•°å­—çš„æ ‡ç­¾é¢„æµ‹å‡†ç¡®æ€§')
    print('=' * 80)
    
    # åŠ è½½è®­ç»ƒæ—¶çš„è¯æ±‡è¡¨
    with open('generated_sequences_super_enhanced/vocab.json', 'r') as f:
        vocab = json.load(f)
    inv_vocab = {v: k for k, v in vocab.items()}
    
    # æŸ¥æ‰¾æ ‡ç­¾token
    label_tokens = {}
    for token, idx in vocab.items():
        if '<CLS_' in token and '>' in token:
            label = token.replace('<CLS_', '').replace('>', '')
            if label.isdigit():
                label_tokens[int(label)] = idx
    
    print(f'âœ… æ‰¾åˆ°{len(label_tokens)}ä¸ªæ•°å­—æ ‡ç­¾token')
    
    # åŠ è½½æ¨¡å‹
    model = GPT2LMHeadModel.from_pretrained('outputs/best_model')
    model.eval()
    device = 'cpu'
    model = model.to(device)
    print(f'âœ… æ¨¡å‹åŠ è½½æˆåŠŸ')
    
    # åŠ è½½æ‰€æœ‰æµ‹è¯•æ ·æœ¬
    all_samples = []
    with open('generated_sequences_super_enhanced/sequences_labels_fixed.jsonl', 'r') as f:
        for line in f:
            if line.strip():
                all_samples.append(json.loads(line.strip()))
    
    print(f'âœ… åŠ è½½{len(all_samples)}ä¸ªæµ‹è¯•æ ·æœ¬')
    
    # æŒ‰æ•°å­—åˆ†ç»„æ ·æœ¬
    samples_by_digit = defaultdict(list)
    for sample in all_samples:
        samples_by_digit[sample['label']].append(sample)
    
    # ä»æ¯ä¸ªæ•°å­—ä¸­éšæœºé€‰æ‹©10ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    test_samples = []
    samples_per_digit = 10
    
    for digit in range(10):
        if digit in samples_by_digit:
            digit_samples = samples_by_digit[digit]
            # éšæœºé€‰æ‹©æ ·æœ¬
            selected = random.sample(digit_samples, min(samples_per_digit, len(digit_samples)))
            test_samples.extend(selected)
    
    random.shuffle(test_samples)  # æ‰“ä¹±é¡ºåº
    print(f'âœ… é€‰æ‹©äº†{len(test_samples)}ä¸ªæµ‹è¯•æ ·æœ¬ï¼ˆæ¯ä¸ªæ•°å­—{samples_per_digit}ä¸ªï¼‰')
    
    # æµ‹è¯•å‡†ç¡®æ€§
    correct_predictions = 0
    total_predictions = 0
    label_accuracy = defaultdict(lambda: {'correct': 0, 'total': 0})
    confusion_matrix = defaultdict(lambda: defaultdict(int))
    
    print('\nğŸ§ª å¼€å§‹æµ‹è¯•...')
    
    for i, sample in enumerate(test_samples):
        if (i + 1) % 20 == 0:
            print(f'   è¿›åº¦: {i+1}/{len(test_samples)}')
        
        true_label = sample['label']
        tokens = sample['tokens'].split()
        
        # æ‰¾åˆ°<CLS>ä½ç½®
        try:
            cls_pos = tokens.index('<CLS>')
            input_tokens = tokens[:cls_pos+1]
        except ValueError:
            continue
        
        # è½¬æ¢ä¸ºIDåºåˆ—å¹¶æˆªæ–­
        input_ids = [vocab.get(t, vocab['<UNK>']) for t in input_tokens]
        max_len = min(len(input_ids), 400)
        input_ids = input_ids[:max_len]
        
        # è¿›è¡Œé¢„æµ‹
        input_tensor = torch.tensor([input_ids], dtype=torch.long)
        with torch.no_grad():
            outputs = model(input_tensor)
            logits = outputs.logits[0, -1, :]
            probs = torch.softmax(logits, dim=-1)
        
        # æ£€æŸ¥æ‰€æœ‰æ ‡ç­¾tokençš„æ¦‚ç‡
        label_probs = {}
        for label_num, token_id in label_tokens.items():
            label_probs[label_num] = probs[token_id].item()
        
        # æ‰¾åˆ°æ¦‚ç‡æœ€é«˜çš„æ ‡ç­¾
        if label_probs:
            predicted_label = max(label_probs, key=label_probs.get)
            
            # ç»Ÿè®¡
            total_predictions += 1
            label_accuracy[true_label]['total'] += 1
            confusion_matrix[true_label][predicted_label] += 1
            
            if predicted_label == true_label:
                correct_predictions += 1
                label_accuracy[true_label]['correct'] += 1
    
    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    overall_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
    
    print('\n' + '=' * 80)
    print('ğŸ“ˆ è¯¦ç»†æµ‹è¯•ç»“æœ')
    print('=' * 80)
    print(f'æ€»ä½“å‡†ç¡®ç‡: {correct_predictions}/{total_predictions} = {overall_accuracy:.2%}')
    
    print('\nğŸ“Š å„æ•°å­—çš„é¢„æµ‹å‡†ç¡®ç‡:')
    for label in sorted(label_accuracy.keys()):
        acc_data = label_accuracy[label]
        if acc_data['total'] > 0:
            acc_rate = acc_data['correct'] / acc_data['total']
            print(f'   æ•°å­— {label}: {acc_data["correct"]}/{acc_data["total"]} = {acc_rate:.2%}')
    
    # æ˜¾ç¤ºæ··æ·†çŸ©é˜µ
    print('\nğŸ“‹ æ··æ·†çŸ©é˜µ (è¡Œ=çœŸå®æ ‡ç­¾, åˆ—=é¢„æµ‹æ ‡ç­¾):')
    print('     ', end='')
    for pred in range(10):
        print(f'{pred:4d}', end='')
    print()
    
    for true in range(10):
        print(f'{true:2d}: ', end='')
        for pred in range(10):
            count = confusion_matrix[true][pred]
            print(f'{count:4d}', end='')
        print()
    
    # æ‰¾å‡ºæœ€å®¹æ˜“æ··æ·†çš„æ•°å­—å¯¹
    print('\nğŸ” æœ€å®¹æ˜“æ··æ·†çš„æ•°å­—å¯¹:')
    confusion_pairs = []
    for true in range(10):
        for pred in range(10):
            if true != pred and confusion_matrix[true][pred] > 0:
                confusion_pairs.append((true, pred, confusion_matrix[true][pred]))
    
    confusion_pairs.sort(key=lambda x: x[2], reverse=True)
    for i, (true, pred, count) in enumerate(confusion_pairs[:5]):
        print(f'   {i+1}. æ•°å­—{true} è¢«è¯¯è®¤ä¸º æ•°å­—{pred}: {count} æ¬¡')
    
    # åˆ†æç»“æœ
    print('\nğŸ” ç»“æœåˆ†æ:')
    if overall_accuracy > 0.8:
        print('   ğŸ‰ æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼å‡†ç¡®ç‡è¶…è¿‡80%')
    elif overall_accuracy > 0.5:
        print('   ï¿½ï¿½ æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®ç‡è¶…è¿‡50%')
    elif overall_accuracy > 0.2:
        print('   âš ï¸ æ¨¡å‹æœ‰ä¸€å®šé¢„æµ‹èƒ½åŠ›ï¼Œä½†éœ€è¦æ”¹è¿›')
    else:
        print('   âŒ æ¨¡å‹é¢„æµ‹å‡†ç¡®ç‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ')
    
    random_accuracy = 1/len(label_tokens)
    print(f'\nğŸ’¡ éšæœºçŒœæµ‹çš„æœŸæœ›å‡†ç¡®ç‡: {random_accuracy:.2%}')
    if overall_accuracy > random_accuracy:
        improvement = overall_accuracy / random_accuracy
        print(f'ğŸ“ˆ æ¨¡å‹æ¯”éšæœºçŒœæµ‹å¥½ {improvement:.1f} å€')
    
    # ç»™å‡ºæ”¹è¿›å»ºè®®
    print('\nğŸ’¡ æ”¹è¿›å»ºè®®:')
    if overall_accuracy < 0.5:
        print('   - å¯èƒ½éœ€è¦æ›´å¤šçš„è®­ç»ƒè½®æ•°')
        print('   - è€ƒè™‘è°ƒæ•´å­¦ä¹ ç‡æˆ–ä¼˜åŒ–å™¨å‚æ•°')
        print('   - æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®')
        print('   - è€ƒè™‘å¢åŠ æ¨¡å‹å¤æ‚åº¦')
    else:
        print('   - æ¨¡å‹å·²æ˜¾ç¤ºå‡ºå­¦ä¹ èƒ½åŠ›')
        print('   - å¯ä»¥å°è¯•å¾®è°ƒè¶…å‚æ•°è¿›ä¸€æ­¥æå‡')

if __name__ == "__main__":
    main()
