import json
import torch
from transformers import GPT2LMHeadModel
import pandas as pd
from collections import defaultdict

def main():
    print('ğŸ¯ æµ‹è¯•æ¨¡å‹ç”Ÿæˆlabelçš„æ­£ç¡®æ€§')
    print('=' * 80)
    
    # åŠ è½½è®­ç»ƒæ—¶çš„è¯æ±‡è¡¨
    with open('generated_sequences_super_enhanced/vocab.json', 'r') as f:
        vocab = json.load(f)
    inv_vocab = {v: k for k, v in vocab.items()}
    print(f'âœ… åŠ è½½è¯æ±‡è¡¨æˆåŠŸï¼Œå…±{len(vocab)}ä¸ªtoken')
    
    # æŸ¥çœ‹è¯æ±‡è¡¨ä¸­çš„æ ‡ç­¾token
    label_tokens = {}
    print('\nğŸ“‹ è¯æ±‡è¡¨ä¸­çš„æ ‡ç­¾token:')
    for token, idx in vocab.items():
        if '<CLS_' in token and '>' in token:
            label = token.replace('<CLS_', '').replace('>', '')
            if label.isdigit():
                label_tokens[int(label)] = idx
                print(f'   {token}: ID {idx}')
    
    print(f'\nâœ… æ‰¾åˆ°{len(label_tokens)}ä¸ªæ•°å­—æ ‡ç­¾token')
    
    # åŠ è½½æ¨¡å‹
    model = GPT2LMHeadModel.from_pretrained('outputs/best_model')
    model.eval()
    device = 'cpu'
    model = model.to(device)
    print(f'âœ… æ¨¡å‹åŠ è½½æˆåŠŸ')
    
    # åŠ è½½æ‰€æœ‰æµ‹è¯•æ ·æœ¬ï¼ˆä¸åªæ˜¯å‰å‡ ä¸ªï¼‰
    test_samples = []
    with open('generated_sequences_super_enhanced/sequences_labels_fixed.jsonl', 'r') as f:
        for line in f:
            if line.strip():
                test_samples.append(json.loads(line.strip()))
    
    print(f'âœ… åŠ è½½{len(test_samples)}ä¸ªæµ‹è¯•æ ·æœ¬')
    
    # ç»Ÿè®¡æ¯ä¸ªæ•°å­—çš„æ ·æœ¬æ•°é‡
    label_counts = defaultdict(int)
    for sample in test_samples:
        label_counts[sample['label']] += 1
    
    print('\nğŸ“Š æ•°æ®é›†ä¸­å„æ•°å­—çš„æ ·æœ¬æ•°é‡:')
    for label in sorted(label_counts.keys()):
        print(f'   æ•°å­— {label}: {label_counts[label]} ä¸ªæ ·æœ¬')
    
    # æµ‹è¯•å‡†ç¡®æ€§
    correct_predictions = 0
    total_predictions = 0
    label_accuracy = defaultdict(lambda: {'correct': 0, 'total': 0})
    
    print('\nğŸ§ª å¼€å§‹æµ‹è¯•æ ‡ç­¾é¢„æµ‹å‡†ç¡®æ€§...')
    
    # åªæµ‹è¯•å‰50ä¸ªæ ·æœ¬ä»¥èŠ‚çœæ—¶é—´
    test_count = min(50, len(test_samples))
    print(f'æµ‹è¯•å‰{test_count}ä¸ªæ ·æœ¬')
    
    for i, sample in enumerate(test_samples[:test_count]):
        if (i + 1) % 10 == 0:
            print(f'   è¿›åº¦: {i+1}/{test_count}')
        
        true_label = sample['label']
        tokens = sample['tokens'].split()
        
        # æ‰¾åˆ°<CLS>ä½ç½®
        try:
            cls_pos = tokens.index('<CLS>')
            input_tokens = tokens[:cls_pos+1]
        except ValueError:
            continue
        
        # è½¬æ¢ä¸ºIDåºåˆ—å¹¶æˆªæ–­
        input_ids = [vocab.get(t, vocab['<UNK>']) for t in input_tokens]
        max_len = min(len(input_ids), 400)
        input_ids = input_ids[:max_len]
        
        # è¿›è¡Œé¢„æµ‹
        input_tensor = torch.tensor([input_ids], dtype=torch.long)
        with torch.no_grad():
            outputs = model(input_tensor)
            logits = outputs.logits[0, -1, :]
            probs = torch.softmax(logits, dim=-1)
        
        # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„æ ‡ç­¾tokençš„æ¦‚ç‡
        label_probs = {}
        for label_num, token_id in label_tokens.items():
            label_probs[label_num] = probs[token_id].item()
        
        # æ‰¾åˆ°æ¦‚ç‡æœ€é«˜çš„æ ‡ç­¾
        if label_probs:
            predicted_label = max(label_probs, key=label_probs.get)
            predicted_prob = label_probs[predicted_label]
            
            # ç»Ÿè®¡å‡†ç¡®æ€§
            total_predictions += 1
            label_accuracy[true_label]['total'] += 1
            
            if predicted_label == true_label:
                correct_predictions += 1
                label_accuracy[true_label]['correct'] += 1
            
            # æ˜¾ç¤ºè¯¦ç»†ç»“æœï¼ˆåªæ˜¾ç¤ºå‰10ä¸ªï¼‰
            if i < 10:
                print(f'\nğŸ“Š æ ·æœ¬ {i+1}:')
                print(f'   çœŸå®æ ‡ç­¾: {true_label}')
                print(f'   é¢„æµ‹æ ‡ç­¾: {predicted_label} (æ¦‚ç‡: {predicted_prob:.6f})')
                print(f'   é¢„æµ‹ç»“æœ: {"âœ… æ­£ç¡®" if predicted_label == true_label else "âŒ é”™è¯¯"}')
                
                # æ˜¾ç¤ºæ‰€æœ‰æ ‡ç­¾çš„æ¦‚ç‡
                print(f'   æ‰€æœ‰æ ‡ç­¾æ¦‚ç‡:')
                for label_num in sorted(label_probs.keys()):
                    prob = label_probs[label_num]
                    marker = "ğŸ‘‰" if label_num == predicted_label else "  "
                    print(f'     {marker} æ•°å­—{label_num}: {prob:.6f}')
    
    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    overall_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
    
    print('\n' + '=' * 80)
    print('ğŸ“ˆ æµ‹è¯•ç»“æœç»Ÿè®¡')
    print('=' * 80)
    print(f'æ€»ä½“å‡†ç¡®ç‡: {correct_predictions}/{total_predictions} = {overall_accuracy:.2%}')
    
    print('\nğŸ“Š å„æ•°å­—çš„é¢„æµ‹å‡†ç¡®ç‡:')
    for label in sorted(label_accuracy.keys()):
        acc_data = label_accuracy[label]
        if acc_data['total'] > 0:
            acc_rate = acc_data['correct'] / acc_data['total']
            print(f'   æ•°å­— {label}: {acc_data["correct"]}/{acc_data["total"]} = {acc_rate:.2%}')
    
    # åˆ†æç»“æœ
    print('\nğŸ” ç»“æœåˆ†æ:')
    if overall_accuracy > 0.8:
        print('   ğŸ‰ æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼å‡†ç¡®ç‡è¶…è¿‡80%')
    elif overall_accuracy > 0.5:
        print('   ğŸ‘ æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®ç‡è¶…è¿‡50%')
    elif overall_accuracy > 0.1:
        print('   âš ï¸ æ¨¡å‹æœ‰ä¸€å®šé¢„æµ‹èƒ½åŠ›ï¼Œä½†éœ€è¦æ”¹è¿›')
    else:
        print('   âŒ æ¨¡å‹é¢„æµ‹å‡†ç¡®ç‡è¾ƒä½ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ')
    
    print(f'\nğŸ’¡ éšæœºçŒœæµ‹çš„æœŸæœ›å‡†ç¡®ç‡: {1/len(label_tokens):.2%}')
    if overall_accuracy > 1/len(label_tokens):
        improvement = overall_accuracy / (1/len(label_tokens))
        print(f'ğŸ“ˆ æ¨¡å‹æ¯”éšæœºçŒœæµ‹å¥½ {improvement:.1f} å€')

if __name__ == "__main__":
    main()
